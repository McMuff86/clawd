# OpenClaw Voice Agent â€“ Analyse & Implementierungsplan

Erstellt: 02.02.2026  
Basierend auf: `tasks/OpenClaw_Voice_Agent_Dokumentation.md`

---

## ğŸ“Š StÃ¤rken/SchwÃ¤chen-Analyse

### âœ… StÃ¤rken des vorgeschlagenen Stacks

| Bereich | StÃ¤rke | Bewertung |
|---------|--------|-----------|
| **100% Self-Hosted** | Keine Cloud-Dependencies, keine laufenden API-Kosten | â­â­â­ |
| **Datenschutz** | Alle Daten lokal, DSGVO/DSG-konform by design | â­â­â­ |
| **Hardware vorhanden** | RTX 3090 + Threadripper = ideale Entwicklungsplattform | â­â­â­ |
| **Qwen3-TTS** | State-of-the-art, Voice Cloning, 10 Sprachen, Apache 2.0 | â­â­â­ |
| **Qwen3-TTS Expertise** | Adi hat bereits Erfahrung (Repo, Gradio App, Modelle geladen) | â­â­â­ |
| **Kosten** | ~30-65 CHF/Monat vs. 100-500 CHF Cloud-LÃ¶sungen | â­â­â­ |
| **AVR Framework** | Telefonie-ready, Docker-basiert, modulare Services | â­â­ |
| **Ollama** | BewÃ¤hrt, einfach, OpenAI-kompatible API | â­â­â­ |
| **Erweiterbarkeit** | IntelliPlan-Integration, Tool-Calling, Multi-Agent | â­â­ |

### âŒ SchwÃ¤chen & Risiken

| Bereich | Risiko | Schwere | Mitigation |
|---------|--------|---------|------------|
| **VRAM-Knappheit** | TTS 1.7B (~10GB) + LLM 14B (~10GB) + Overhead = 24GB knapp | ğŸ”´ Hoch | 0.6B TTS oder 7B LLM verwenden; Model-Offloading |
| **Latenz** | Pipeline ASRâ†’LLMâ†’TTS kÃ¶nnte >2s End-to-End sein | ğŸŸ¡ Mittel | Streaming, Vosk statt Whisper, Token-Level TTS |
| **AVR Maturity** | Kleinere Community, weniger Battle-tested als Pipecat | ğŸŸ¡ Mittel | AVR fÃ¼r Telefonie, Pipecat als Backup |
| **Qwen3-TTS Streaming** | Streaming-API StabilitÃ¤t unklar fÃ¼r Produktions-Telefonie | ğŸŸ¡ Mittel | Fallback auf Non-Streaming mit Buffer |
| **Asterisk KomplexitÃ¤t** | PBX-Konfiguration ist komplex, schwer zu debuggen | ğŸŸ¡ Mittel | Schritt-fÃ¼r-Schritt, erst Softphone |
| **GSM Dongle** | chan_dongle ist ein Community-Projekt, KompatibilitÃ¤t variiert | ğŸŸ¡ Mittel | SIP Trunk als Alternative bereithalten |
| **24/7 Betrieb** | Workstation ist nicht fÃ¼r Dauerbetrieb gedacht (Strom, LÃ¤rm) | ğŸŸ¡ Mittel | Erst Workstation, spÃ¤ter Mini-PC |
| **Deutsch ASR** | Vosk Deutsch-Modell ist akzeptabel, nicht perfekt | ğŸŸ¡ Mittel | Whisper als Fallback, Fine-Tuning |
| **Interrupt Handling** | NatÃ¼rliches Unterbrechen (Barge-in) ist komplex | ğŸŸ¡ Mittel | AVR hat Barge-in Support |
| **Single Point of Failure** | Alles auf einer Maschine | ğŸŸ¢ Niedrig | FÃ¼r MVP akzeptabel |

### âš ï¸ Fehlende Aspekte in der Dokumentation

1. **Monitoring & Alerting** â€“ Was passiert wenn ein Service crasht?
2. **Logging & Analytics** â€“ GesprÃ¤chstranskripte, QualitÃ¤tsmetriken
3. **Graceful Degradation** â€“ Was wenn GPU out-of-memory?
4. **Security** â€“ SIP-Sicherheit, Asterisk Hardening
5. **Testing** â€“ Wie testet man Voice-QualitÃ¤t automatisiert?
6. **Update-Strategie** â€“ Wie werden Modelle/Container aktualisiert?
7. **Concurrent Calls** â€“ Was bei 2+ gleichzeitigen Anrufen?
8. **Kontext-Persistenz** â€“ Wie merkt sich der Agent vorherige GesprÃ¤che?
9. **Fallback-Verhalten** â€“ Was wenn der Agent nicht versteht?
10. **Warm-up Zeit** â€“ Model-Loading bei erstem Anruf (~10-20s)

---

## ğŸ—ï¸ Implementierungsplan in Phasen

### Phase 0: Vorbereitung (1-2 Tage) ğŸŸ¢
**Ziel:** Umgebung ready, alle AbhÃ¤ngigkeiten geklÃ¤rt

- [ ] NVIDIA Container Toolkit in WSL2 verifizieren
- [ ] Docker Compose Basis aufsetzen (`~/projects/openclaw-voice-agent/`)
- [ ] Projektstruktur erstellen (config/, models/, logs/, src/)
- [ ] Vosk Deutsch-Modell herunterladen (~1.5GB)
- [ ] Ollama installieren + qwen3:7b laden (erst 7B, sicherer fÃ¼r VRAM)
- [ ] Git Repo initialisieren

**Deliverable:** Leere aber funktionale Docker-Umgebung

---

### Phase 1: TTS-Service (2-3 Tage) ğŸŸ¡
**Ziel:** Qwen3-TTS als eigenstÃ¤ndiger HTTP-Service

- [ ] FastAPI Service fÃ¼r Qwen3-TTS bauen (basierend auf `src/engine.py` vom TTS-Repo!)
- [ ] Dockerfile mit CUDA Support
- [ ] Endpoints: `/health`, `/text-to-speech`, `/text-to-speech-stream`
- [ ] AVR-kompatibles Audio-Format (PCM 16-bit, 8kHz fÃ¼r Telefonie)
- [ ] Resampling von 24kHz TTS-Output auf 8kHz Telefonie
- [ ] Model warm-up bei Container-Start
- [ ] VRAM-Monitoring Endpoint
- [ ] Testen: curl â†’ Audio-File â†’ Abspielen

**Deliverable:** Standalone TTS-Service, aufrufbar via HTTP

**Synergie mit Qwen3-TTS Repo:** 
- `src/engine.py` â†’ Basis fÃ¼r den TTS-Server
- `src/config.py` â†’ Config-Pattern wiederverwenden
- `src/audio_utils.py` â†’ Resampling-Funktionen

---

### Phase 2: ASR + LLM Services (2-3 Tage) ğŸŸ¡
**Ziel:** Speech-to-Text und LLM funktional

- [ ] Vosk ASR Container aufsetzen (AVR Docker Image)
- [ ] Ollama Container mit GPU-Zugriff
- [ ] LLM Adapter (AVR avr-llm-openai Image)
- [ ] System Prompt definieren und testen
- [ ] End-to-End Test: Audio-File â†’ Text â†’ LLM-Antwort â†’ TTS-Audio
- [ ] Latenz messen und dokumentieren

**Deliverable:** Funktionierende ASRâ†’LLMâ†’TTS Pipeline (ohne Telefonie)

---

### Phase 3: AVR Core + WebSocket (2-3 Tage) ğŸŸ¡
**Ziel:** Voice Agent funktioniert Ã¼ber WebSocket

- [ ] AVR Core Container einrichten
- [ ] WebSocket-Transport konfigurieren
- [ ] Silero VAD integrieren
- [ ] Interrupt-Handling (Barge-in) testen
- [ ] Test mit Browser-basiertem Audio-Client
- [ ] Latenz-Optimierung: Streaming Pipeline tunen

**Deliverable:** Funktionierender Voice Agent Ã¼ber WebSocket (Browser)

---

### Phase 4: Asterisk + Softphone (3-4 Tage) ğŸŸ 
**Ziel:** Telefonie-Grundlage steht

- [ ] Asterisk Container aufsetzen
- [ ] PJSIP Basis-Konfiguration
- [ ] AudioSocket Verbindung zu AVR Core
- [ ] Lokaler Softphone-Test (Linphone/Zoiper)
- [ ] Anruf annehmen â†’ Voice Agent antwortet
- [ ] Audio-QualitÃ¤t prÃ¼fen (Codec-Konfiguration)
- [ ] Dialplan fÃ¼r ein- und ausgehende Anrufe

**Deliverable:** Funktionierende Telefonie Ã¼ber lokales Softphone

---

### Phase 5: Echte Telefonie (2-3 Tage) ğŸŸ 
**Ziel:** Erreichbar Ã¼ber echte Telefonnummer

- [ ] Option A: GSM Dongle + chan_dongle ODER
- [ ] Option B: SIP Trunk (sipgate/peoplefone)
- [ ] Konfiguration in Asterisk
- [ ] Test mit echtem Telefonanruf
- [ ] Audio-QualitÃ¤t Ã¼ber Mobilfunk prÃ¼fen
- [ ] Robustheit: Was bei schlechter Verbindung?

**Deliverable:** Voice Agent Ã¼ber echte Telefonnummer erreichbar

---

### Phase 6: Intelligence & Integration (ongoing) ğŸ”µ
**Ziel:** NÃ¼tzliche Features, IntelliPlan-Anbindung

- [ ] Tool-Calling fÃ¼r Ollama konfigurieren
- [ ] Kalender-Abfrage (Google Calendar via gog)
- [ ] Erinnerungen setzen per Sprachbefehl
- [ ] IntelliPlan API-Anbindung (Projekte, Tasks)
- [ ] GesprÃ¤chstranskripte speichern
- [ ] Kontext-Persistenz Ã¼ber Anrufe hinweg
- [ ] Voice Cloning mit Adis Stimme

---

## ğŸ“ Technische Entscheidungen

### VRAM-Strategie (kritisch!)

**Option A: Shared GPU (RTX 3090)**
```
Qwen3-TTS 0.6B  â†’  ~4 GB
Ollama qwen3:7b  â†’ ~5 GB
Vosk             â†’  CPU (0 GB GPU)
Silero VAD       â†’  CPU (<1 MB)
Reserve          â†’  ~15 GB frei
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: ~9 GB / 24 GB âœ… Komfortabel
```

**Option B: Maximale QualitÃ¤t**
```
Qwen3-TTS 1.7B  â†’ ~10 GB
Ollama qwen3:14b â†’ ~10 GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: ~20 GB / 24 GB âš ï¸ Knapp
```

**Empfehlung:** Start mit Option A (0.6B + 7B), upgrade wenn stabil.

### Latenz-Budget

| Schritt | Ziel | Worst Case |
|---------|------|------------|
| VAD â†’ Sprache erkannt | <100ms | 200ms |
| ASR (Vosk) | <200ms | 500ms |
| LLM (7B, 2-3 SÃ¤tze) | <500ms | 1500ms |
| TTS (0.6B, Streaming) | <200ms first token | 500ms |
| **Total** | **<1000ms** | **<2700ms** |

Ziel: <1.5 Sekunden End-to-End fÃ¼r natÃ¼rliche Konversation.

### Audio-Format Konvertierung

```
Telefon (8kHz Î¼-law) â†’ Asterisk â†’ PCM 16-bit â†’ Vosk (16kHz)
                                                     â†“
Telefon (8kHz Î¼-law) â† Asterisk â† PCM 16-bit â† TTS (24kHz â†’ resample)
```

---

## ğŸ—“ï¸ ZeitschÃ¤tzung

| Phase | Dauer | AbhÃ¤ngigkeit |
|-------|-------|-------------|
| Phase 0: Vorbereitung | 1-2 Tage | - |
| Phase 1: TTS-Service | 2-3 Tage | Phase 0 |
| Phase 2: ASR + LLM | 2-3 Tage | Phase 0 |
| Phase 3: AVR Core | 2-3 Tage | Phase 1 + 2 |
| Phase 4: Asterisk | 3-4 Tage | Phase 3 |
| Phase 5: Telefonie | 2-3 Tage | Phase 4 |
| Phase 6: Integration | Ongoing | Phase 5 |
| **Total bis MVP** | **~12-18 Tage** | |

*Bei ~2h/Abend Arbeitszeit = ~6-9 Wochen realistisch.*

---

## ğŸ”„ Beziehung zu anderen Projekten

### Qwen3-TTS Voice Clone Repo
- `src/engine.py` â†’ Direkte Wiederverwendung fÃ¼r TTS-Service
- `src/config.py` â†’ Config-Pattern
- `src/audio_utils.py` â†’ Resampling-Funktionen
- Voice Cloning Feature â†’ Adis Stimme fÃ¼r den Agent

### IntelliPlan
- REST-API als Tool fÃ¼r den Voice Agent
- Projekte/Tasks per Sprache abrufen/erstellen
- Termine per Sprachbefehl planen

### OpenClaw (Sentinel)
- Sentinel als "Gehirn" hinter dem Voice Agent?
- Oder separater Agent mit eigenem LLM?
- â†’ Entscheidung in Phase 6

---

## âœ… NÃ¤chste konkrete Schritte

1. **NVIDIA Container Toolkit testen** (`docker run --gpus all nvidia/cuda:12.1-base nvidia-smi`)
2. **Projektstruktur erstellen** (`~/projects/openclaw-voice-agent/`)
3. **Vosk-Modell downloaden**
4. **TTS-Service Dockerfile schreiben** (basierend auf Qwen3-TTS engine.py)
5. **Docker Compose v1** (TTS + Vosk + Ollama)

---

*Dieses Dokument wird aktualisiert sobald Phasen abgeschlossen werden.*
